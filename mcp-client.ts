import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";
import * as dotenv from "dotenv";
import { OpenAI } from "openai";
import { ChatCompletionMessageParam } from "openai/resources/index.mjs";
import readline from "readline";

dotenv.config();
const openaiApiKey = process.env.OPENAI_API_KEY;
if (!openaiApiKey) throw new Error("æœªè®¾ç½® OPENAI_API_KEY");

const client = new Client({ name: "mcp-client", version: "1.0.0" });

async function runClient(serverPath: string) {
    // è¿æ¥åˆ° MCP æœåŠ¡å™¨
    const transport = new StdioClientTransport({ command: "node", args: [serverPath] });
    await client.connect(transport);
    console.log("å·²è¿æ¥åˆ° MCP æœåŠ¡å™¨ï¼Œå·¥å…·åˆ—è¡¨ï¼š", (await client.listTools()).tools.map(t => t.name));

    // ç®€å•çš„äº¤äº’å¼å¯¹è¯å¾ªç¯
    const rl = readline.createInterface({ input: process.stdin, output: process.stdout });
    console.log("è¾“å…¥ 'quit' é€€å‡ºã€‚");
    while (true) {
        const query: string = await new Promise(res => rl.question("è¾“å…¥æŸ¥è¯¢ï¼š", res));
        if (query.toLowerCase() === "quit") break;
        const openai = new OpenAI({
            baseURL: 'https://api.deepseek.com',
            apiKey: openaiApiKey
        });
        // MCP ä¼šåœ¨æ¨¡å‹å›ç­”ä¸­æ’å…¥è°ƒç”¨å·¥å…·çš„æŒ‡ä»¤ï¼ˆcontent.type ä¸º "tool_use"ï¼‰
        const message: ChatCompletionMessageParam[] = [{ role: "user", content: query }];
        const result = await openai.chat.completions.create({
            model: "deepseek-chat",
            messages: message,
        });
        console.log("ğŸš€ ~ file: index.ts:32 ~ result:", result, 'content', result.choices[0].message.content)

        // å¤„ç†æ¨¡å‹è¾“å‡ºï¼šå¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œåˆ™æ‰§è¡Œå¹¶åé¦ˆ
        // let finalAnswer = "";
        // for (const content of result.choices) {
        //     if (content.type === "text") {
        //         finalAnswer += content.text;
        //     } else if (content.type === "tool_use") {
        //         const toolName = content.name!;
        //         const args = content.input as Record<string, any> || {};
        //         console.log(`æ¨¡å‹è¯·æ±‚å·¥å…· ${toolName}ï¼Œå‚æ•°ï¼š`, args);

        //         // è°ƒç”¨ MCP å·¥å…·
        //         const toolResult = await client.callTool({ name: toolName, arguments: args });
        //         const toolText = toolResult.content as string;
        //         console.log(`å·¥å…·è¿”å›ï¼š${toolText}`);

        //         // å°†å·¥å…·ç»“æœå½“ä½œç”¨æˆ·æ¶ˆæ¯åé¦ˆç»™æ¨¡å‹
        //         anthMessage.push({ role: "assistant", content: content.text }); // æ¨¡å‹æå‡ºè°ƒç”¨å·¥å…·
        //         anthMessage.push({ role: "user", content: toolText });         // å·¥å…·ç»“æœä½œä¸ºç”¨æˆ·è¾“å…¥

        //         // è®©æ¨¡å‹æ ¹æ®æ–°ä¿¡æ¯ç»§ç»­å¯¹è¯
        //         const next = await anthropic.messages.create({
        //             model: "claude-3-5-sonnet-20241022",
        //             max_tokens: 500,
        //             messages: anthMessage,
        //         });
        //         for (const n of next.content) {
        //             if (n.type === "text") finalAnswer += n.text;
        //         }
        //     }
        // }
        console.log("\næ¨¡å‹å›ç­”ï¼š", result.choices[0].message.content);
    }
    rl.close();
    await client.close();
}

// å‘½ä»¤è¡Œå‚æ•°ï¼šä¼ å…¥æœåŠ¡å™¨è„šæœ¬è·¯å¾„
const serverScript = process.argv[2];
if (!serverScript) {
    console.log("ç”¨æ³•: npm run start <æœåŠ¡å™¨æ„å»ºè„šæœ¬è·¯å¾„>");
    process.exit(1);
}
runClient(serverScript).catch(console.error);
